{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "tensorflow 01-speech-commands-mfcc-extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Embeddedkuba/wakewords/blob/main/tensorflow_01_speech_commands_mfcc_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDCoOM3E8awt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4492450c-0ae0-467d-b17f-0113e7213379"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install python_speech_features\n",
        "import python_speech_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp37-none-any.whl size=5887 sha256=50db56e719971073b5694fc67d2509eaea79b9a4bc9d91dce1cd3ecd327623f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRsGJQzC-t2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d5f9a5-ddbd-49a5-9fa5-8b486209c8be"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCsOKCZe_crN"
      },
      "source": [
        "path = \"/content/drive/MyDrive/datasets\"\n",
        "\n",
        "df_bonus = pd.read_csv(path)\n",
        "# Dataset is now stored in a Pandas Dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnGNGJJe8awz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3a6ad5-4024-4722-d9b4-1bd4568a2bf9"
      },
      "source": [
        "# Dataset path and view possible targets\n",
        "dataset_path = '/content/drive/MyDrive/datasets'\n",
        "for name in listdir(dataset_path):\n",
        "    if isdir(join(dataset_path, name)):\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PawnToA2\n",
            "PawnToA3\n",
            "PawnToA1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRe7Avm18aw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3a497b-c466-4571-cb17-4e0b3419c032"
      },
      "source": [
        "# Create an all targets list\n",
        "all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
        "print(all_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['PawnToA2', 'PawnToA3', 'PawnToA1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHqyGs-F8aw0"
      },
      "source": [
        "# Leave off background noise set\n",
        "all_targets.remove('_background_noise_')\n",
        "print(all_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l1Oj63d8aw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6a0732-f3fb-42b2-fa98-651fbb4f01f7"
      },
      "source": [
        "# See how many files are in each\n",
        "num_samples = 0\n",
        "for target in all_targets:\n",
        "    print(len(listdir(join(dataset_path, target))))\n",
        "    num_samples += len(listdir(join(dataset_path, target)))\n",
        "print('Total samples:', num_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "50\n",
            "50\n",
            "Total samples: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjIpunqE8aw1"
      },
      "source": [
        "# Settings\n",
        "target_list = all_targets\n",
        "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
        "perc_keep_samples = 1.0 # 1.0 is keep all samples\n",
        "val_ratio = 1\n",
        "test_ratio = 1\n",
        "sample_rate = 8000\n",
        "num_mfcc = 16\n",
        "len_mfcc = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGR5Z0Mj8aw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ade8e6b-6282-4a54-8f9b-296a39042e2e"
      },
      "source": [
        "# Create list of filenames along with ground truth vector (y)\n",
        "filenames = []\n",
        "y = []\n",
        "for index, target in enumerate(target_list):\n",
        "    print(join(dataset_path, target))\n",
        "    filenames.append(listdir(join(dataset_path, target)))\n",
        "    y.append(np.ones(len(filenames[index])) * index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/datasets/PawnToA2\n",
            "/content/drive/MyDrive/datasets/PawnToA3\n",
            "/content/drive/MyDrive/datasets/PawnToA1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Bk1h5F8aw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4b7efd-5b0e-411d-f72b-4c3b88657ca2"
      },
      "source": [
        "# Check ground truth Y vector\n",
        "print(y)\n",
        "for item in y:\n",
        "    print(len(item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
            "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
            "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])]\n",
            "50\n",
            "50\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzV4nq_m8aw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f1b41995-852f-4319-a344-a2a0cf23f3c9"
      },
      "source": [
        "# Flatten filename and y vectors\n",
        "filenames = [item for sublist in filenames for item in sublist]\n",
        "y = [item for sublist in y for item in sublist]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-31d987606761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Flatten filename and y vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-31d987606761>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Flatten filename and y vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PjzKmGB8aw2"
      },
      "source": [
        "# Associate filenames with true output and shuffle\n",
        "filenames_y = list(zip(filenames, y))\n",
        "random.shuffle(filenames_y)\n",
        "filenames, y = zip(*filenames_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhI0JKiI8aw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343c43bc-c56e-438e-c081-fd3fc8e39314"
      },
      "source": [
        "# Only keep the specified number of samples (shorter extraction/training)\n",
        "print(len(filenames))\n",
        "filenames = filenames[:int(len(filenames) * perc_keep_samples)]\n",
        "print(len(filenames))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2828\n",
            "2828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU-N8NAU8aw2"
      },
      "source": [
        "# Calculate validation and test set sizes\n",
        "val_set_size = int(len(filenames) * val_ratio)\n",
        "test_set_size = int(len(filenames) * test_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA2_ikuO8aw3"
      },
      "source": [
        "# Break dataset apart into train, validation, and test sets\n",
        "filenames_val = filenames[:val_set_size]\n",
        "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\n",
        "filenames_train = filenames[(val_set_size + test_set_size):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK9MVUls8aw3"
      },
      "source": [
        "# Break y apart into train, validation, and test sets\n",
        "y_orig_val = y[:val_set_size]\n",
        "y_orig_test = y[val_set_size:(val_set_size + test_set_size)]\n",
        "y_orig_train = y[(val_set_size + test_set_size):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnOLy5498aw3"
      },
      "source": [
        "# Function: Create MFCC from given path\n",
        "def calc_mfcc(path):\n",
        "    \n",
        "    # Load wavefile\n",
        "    signal, fs = librosa.load(path, sr=sample_rate)\n",
        "    \n",
        "    # Create MFCCs from sound clip\n",
        "    mfccs = python_speech_features.base.mfcc(signal, \n",
        "                                            samplerate=fs,\n",
        "                                            winlen=0.256,\n",
        "                                            winstep=0.050,\n",
        "                                            numcep=num_mfcc,\n",
        "                                            nfilt=26,\n",
        "                                            nfft=2048,\n",
        "                                            preemph=0.0,\n",
        "                                            ceplifter=0,\n",
        "                                            appendEnergy=False,\n",
        "                                            winfunc=np.hanning)\n",
        "    return mfccs.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQnBWUQj8aw3"
      },
      "source": [
        "# TEST: Construct test set by computing MFCC of each WAV file\n",
        "prob_cnt = 0\n",
        "x_test = []\n",
        "y_test = []\n",
        "for index, filename in enumerate(filenames_train):\n",
        "    \n",
        "    # Stop after 500\n",
        "    if index >= 500:\n",
        "        break\n",
        "    \n",
        "    # Create path from given filename and target item\n",
        "    path = join(dataset_path, target_list[int(y_orig_train[index])], \n",
        "                filename)\n",
        "    \n",
        "    # Create MFCCs\n",
        "    mfccs = calc_mfcc(path)\n",
        "    \n",
        "    if mfccs.shape[1] == len_mfcc:\n",
        "        x_test.append(mfccs)\n",
        "        y_test.append(y_orig_train[index])\n",
        "    else:\n",
        "        print('Dropped:', index, mfccs.shape)\n",
        "        prob_cnt += 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGO31N2V8aw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cc1be3-6a62-4689-9f99-f78de9e92257"
      },
      "source": [
        "print('% of problematic samples:', prob_cnt / 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of problematic samples: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRaaEV728aw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "143e1504-07ac-4153-e211-b560d6914211"
      },
      "source": [
        "# TEST: Test shorter MFCC\n",
        "#!pip install playsound\n",
        "from playsound import playsound\n",
        "\n",
        "idx = 13\n",
        "\n",
        "# Create path from given filename and target item\n",
        "path = join(dataset_path, target_list[int(y_orig_train[idx])], \n",
        "            filenames_train[idx])\n",
        "\n",
        "# Create MFCCs\n",
        "mfccs = calc_mfcc(path)\n",
        "print(\"MFCCs:\", mfccs)\n",
        "\n",
        "# Plot MFCC\n",
        "fig = plt.figure()\n",
        "plt.imshow(mfccs, cmap='inferno', origin='lower')\n",
        "\n",
        "# TEST: Play problem sounds\n",
        "print(target_list[int(y_orig_train[idx])])\n",
        "playsound(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b7df40a7505a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create path from given filename and target item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m path = join(dataset_path, target_list[int(y_orig_train[idx])], \n\u001b[0m\u001b[1;32m      9\u001b[0m             filenames_train[idx])\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeQnQZof8aw4"
      },
      "source": [
        "# Function: Create MFCCs, keeping only ones of desired length\n",
        "def extract_features(in_files, in_y):\n",
        "    prob_cnt = 0\n",
        "    out_x = []\n",
        "    out_y = []\n",
        "        \n",
        "    for index, filename in enumerate(in_files):\n",
        "    \n",
        "        # Create path from given filename and target item\n",
        "        path = join(dataset_path, target_list[int(in_y[index])], \n",
        "                    filename)\n",
        "        \n",
        "        # Check to make sure we're reading a .wav file\n",
        "        if not path.endswith('.wav'):\n",
        "            continue\n",
        "\n",
        "        # Create MFCCs\n",
        "        mfccs = calc_mfcc(path)\n",
        "\n",
        "        # Only keep MFCCs with given length\n",
        "        if mfccs.shape[1] == len_mfcc:\n",
        "            out_x.append(mfccs)\n",
        "            out_y.append(in_y[index])\n",
        "        else:\n",
        "            print('Dropped:', index, mfccs.shape)\n",
        "            prob_cnt += 1\n",
        "            \n",
        "    return out_x, out_y, prob_cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rUdp_kS8aw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "732ded44-fadb-437a-f30d-67105fe28bbc"
      },
      "source": [
        "# Create train, validation, and test sets\n",
        "x_train, y_train, prob = extract_features(filenames_train, \n",
        "                                          y_orig_train)\n",
        "print('Removed percentage:', prob / len(y_orig_train))\n",
        "x_val, y_val, prob = extract_features(filenames_val, y_orig_val)\n",
        "print('Removed percentage:', prob / len(y_orig_val))\n",
        "x_test, y_test, prob = extract_features(filenames_test, y_orig_test)\n",
        "print('Removed percentage:', prob / len(y_orig_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-83d06da0c29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m x_train, y_train, prob = extract_features(filenames_train, \n\u001b[1;32m      3\u001b[0m                                           y_orig_train)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Removed percentage:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_orig_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_orig_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Removed percentage:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_orig_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzWOL1288aw5"
      },
      "source": [
        "# Save features and truth vector (y) sets to disk\n",
        "np.savez(feature_sets_file, \n",
        "         x_train=x_train, \n",
        "         y_train=y_train, \n",
        "         x_val=x_val, \n",
        "         y_val=y_val, \n",
        "         x_test=x_test, \n",
        "         y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG5ISYGe8aw5"
      },
      "source": [
        "# TEST: Load features\n",
        "feature_sets = np.load(feature_sets_file)\n",
        "feature_sets.files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOr2baNr8aw5"
      },
      "source": [
        "len(feature_sets['x_train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZqPdvO48aw6"
      },
      "source": [
        "print(feature_sets['y_val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rej9Apc28aw6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}